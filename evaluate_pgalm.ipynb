{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# P-GALM Framework Evaluation\n",
                "\n",
                "This notebook evaluates the Probabilistic Graph-Augmented Language Model (P-GALM) on a subset of the ScienceQA dataset. \n",
                "\n",
                "It performs the following steps:\n",
                "1.  Loads the ScienceQA validation dataset.\n",
                "2.  Selects a random sample of questions.\n",
                "3.  Runs the vPGM inference pipeline on each question.\n",
                "4.  Compares the predicted answer with the ground truth.\n",
                "5.  Calculates accuracy and displays detailed results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "c:\\Users\\shafi\\anaconda3\\envs\\PGM\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                        "  from .autonotebook import tqdm as notebook_tqdm\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import json\n",
                "import random\n",
                "import pandas as pd\n",
                "from tqdm import tqdm\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# Load environment variables (OPENAI_API_KEY)\n",
                "load_dotenv()\n",
                "\n",
                "# Import P-GALM modules\n",
                "from scienceqa_vpgm_loader import load_scienceqa, load_prompt_template, build_scienceqa_skeleton\n",
                "from vpgm_llm_client import infer_vpgm_for_skeleton"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "SAMPLE_SIZE = 10  # Number of questions to evaluate\n",
                "SPLIT = \"validation\"\n",
                "TEMPLATE_ID = \"scienceqa_vpgm_4latent_generic\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading dataset and template...\n",
                        "Loaded 4241 examples from validation split.\n"
                    ]
                }
            ],
            "source": [
                "print(\"Loading dataset and template...\")\n",
                "dataset = load_scienceqa(split=SPLIT)\n",
                "template = load_prompt_template()\n",
                "print(f\"Loaded {len(dataset)} examples from {SPLIT} split.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Found 2144 text-only questions.\n",
                        "Selected 10 questions for evaluation.\n"
                    ]
                }
            ],
            "source": [
                "# Select a random sample\n",
                "# Filter out images for this evaluation to focus on text reasoning, or keep them if you want full eval\n",
                "# For this demo, we'll try to pick text-only questions to avoid potential image processing issues if any,\n",
                "# but the pipeline supports images if they are handled correctly.\n",
                "\n",
                "candidates = [ex for ex in dataset if ex.get('image') is None]\n",
                "print(f\"Found {len(candidates)} text-only questions.\")\n",
                "\n",
                "if len(candidates) < SAMPLE_SIZE:\n",
                "    sample = candidates\n",
                "else:\n",
                "    sample = random.sample(candidates, SAMPLE_SIZE)\n",
                "\n",
                "print(f\"Selected {len(sample)} questions for evaluation.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Starting inference...\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 10/10 [02:16<00:00, 13.67s/it]\n"
                    ]
                }
            ],
            "source": [
                "results = []\n",
                "\n",
                "print(\"Starting inference...\")\n",
                "for i, ex in enumerate(tqdm(sample)):\n",
                "    # 1. Build Skeleton\n",
                "    # Use index as synthetic ID if needed\n",
                "    sqa_id = ex.get(\"id\") or ex.get(\"qid\") or f\"sample_{i}\"\n",
                "    skeleton = build_scienceqa_skeleton(ex, TEMPLATE_ID, template, override_id=sqa_id)\n",
                "    \n",
                "    # 2. Run Inference\n",
                "    try:\n",
                "        prediction_result = infer_vpgm_for_skeleton(skeleton, template, template_id=TEMPLATE_ID)\n",
                "        \n",
                "        # 3. Extract Answer\n",
                "        # The model returns 'selected_answer' which is the text of the option.\n",
                "        # We need to map it back to the index (0, 1, 2...)\n",
                "        selected_text = prediction_result[\"answer_posterior\"][\"selected_answer\"]\n",
                "        options = ex[\"choices\"]\n",
                "        \n",
                "        # Simple exact match or substring match\n",
                "        pred_index = -1\n",
                "        if selected_text in options:\n",
                "            pred_index = options.index(selected_text)\n",
                "        else:\n",
                "            # Fallback: try to find which option is contained in the selected text\n",
                "            for idx, opt in enumerate(options):\n",
                "                if opt in selected_text or selected_text in opt:\n",
                "                    pred_index = idx\n",
                "                    break\n",
                "        \n",
                "        # 4. Compare with Ground Truth\n",
                "        ground_truth_index = ex[\"answer\"]\n",
                "        is_correct = (pred_index == ground_truth_index)\n",
                "        \n",
                "        results.append({\n",
                "            \"id\": sqa_id,\n",
                "            \"question\": ex[\"question\"],\n",
                "            \"ground_truth_index\": ground_truth_index,\n",
                "            \"ground_truth_text\": options[ground_truth_index],\n",
                "            \"predicted_index\": pred_index,\n",
                "            \"predicted_text\": selected_text,\n",
                "            \"is_correct\": is_correct,\n",
                "            \"reasoning_quality\": prediction_result[\"latent_posteriors\"][\"Z4_logical_reasoning\"][\"justification\"]\n",
                "        })\n",
                "        \n",
                "    except Exception as e:\n",
                "        print(f\"Error processing {sqa_id}: {e}\")\n",
                "        results.append({\n",
                "            \"id\": sqa_id,\n",
                "            \"question\": ex[\"question\"],\n",
                "            \"ground_truth_index\": ex[\"answer\"],\n",
                "            \"ground_truth_text\": ex[\"choices\"][ex[\"answer\"]],\n",
                "            \"predicted_index\": -1,\n",
                "            \"predicted_text\": \"ERROR\",\n",
                "            \"is_correct\": False,\n",
                "            \"reasoning_quality\": str(e)\n",
                "        })"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Overall Accuracy: 100.00%\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>question</th>\n",
                            "      <th>ground_truth_text</th>\n",
                            "      <th>predicted_text</th>\n",
                            "      <th>is_correct</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>Which is smoother?</td>\n",
                            "      <td>plastic bag</td>\n",
                            "      <td>plastic bag</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>What information supports the conclusion that Rudy inherited this trait?</td>\n",
                            "      <td>Rudy's biological father has curly hair.</td>\n",
                            "      <td>Rudy's biological father has curly hair.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>What information supports the conclusion that Tony acquired this trait?</td>\n",
                            "      <td>Tony's scar was caused by an accident. He cut his arm when he fell off his bicycle.</td>\n",
                            "      <td>Tony's scar was caused by an accident. He cut his arm when he fell off his bicycle.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>Which is a run-on sentence?</td>\n",
                            "      <td>Will picked apples, he will give some away.</td>\n",
                            "      <td>Will picked apples, he will give some away.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>What do these two changes have in common?\\nbreaking a ceramic plate\\npicking up a paper clip wit...</td>\n",
                            "      <td>Both are only physical changes.</td>\n",
                            "      <td>Both are only physical changes.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>5</th>\n",
                            "      <td>What is the mass of a full bag of groceries?</td>\n",
                            "      <td>5 pounds</td>\n",
                            "      <td>5 pounds</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>6</th>\n",
                            "      <td>Which of the following contains a vague pronoun reference?</td>\n",
                            "      <td>Jake and his best friend go to the same college, but he is graduating this coming June.</td>\n",
                            "      <td>Jake and his best friend go to the same college, but he is graduating this coming June.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>7</th>\n",
                            "      <td>Would you find the word throb on a dictionary page with the following guide words?\\ntaper - tent...</td>\n",
                            "      <td>no</td>\n",
                            "      <td>no</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>8</th>\n",
                            "      <td>Which is a complete sentence?</td>\n",
                            "      <td>My family will swim at the town pool tomorrow.</td>\n",
                            "      <td>My family will swim at the town pool tomorrow.</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>9</th>\n",
                            "      <td>Is teaching art a good or a service?</td>\n",
                            "      <td>a service</td>\n",
                            "      <td>a service</td>\n",
                            "      <td>True</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                                                              question  \\\n",
                            "0                                                                                   Which is smoother?   \n",
                            "1                             What information supports the conclusion that Rudy inherited this trait?   \n",
                            "2                              What information supports the conclusion that Tony acquired this trait?   \n",
                            "3                                                                          Which is a run-on sentence?   \n",
                            "4  What do these two changes have in common?\\nbreaking a ceramic plate\\npicking up a paper clip wit...   \n",
                            "5                                                         What is the mass of a full bag of groceries?   \n",
                            "6                                           Which of the following contains a vague pronoun reference?   \n",
                            "7  Would you find the word throb on a dictionary page with the following guide words?\\ntaper - tent...   \n",
                            "8                                                                        Which is a complete sentence?   \n",
                            "9                                                                 Is teaching art a good or a service?   \n",
                            "\n",
                            "                                                                         ground_truth_text  \\\n",
                            "0                                                                              plastic bag   \n",
                            "1                                                 Rudy's biological father has curly hair.   \n",
                            "2      Tony's scar was caused by an accident. He cut his arm when he fell off his bicycle.   \n",
                            "3                                              Will picked apples, he will give some away.   \n",
                            "4                                                          Both are only physical changes.   \n",
                            "5                                                                                 5 pounds   \n",
                            "6  Jake and his best friend go to the same college, but he is graduating this coming June.   \n",
                            "7                                                                                       no   \n",
                            "8                                           My family will swim at the town pool tomorrow.   \n",
                            "9                                                                                a service   \n",
                            "\n",
                            "                                                                            predicted_text  \\\n",
                            "0                                                                              plastic bag   \n",
                            "1                                                 Rudy's biological father has curly hair.   \n",
                            "2      Tony's scar was caused by an accident. He cut his arm when he fell off his bicycle.   \n",
                            "3                                              Will picked apples, he will give some away.   \n",
                            "4                                                          Both are only physical changes.   \n",
                            "5                                                                                 5 pounds   \n",
                            "6  Jake and his best friend go to the same college, but he is graduating this coming June.   \n",
                            "7                                                                                       no   \n",
                            "8                                           My family will swim at the town pool tomorrow.   \n",
                            "9                                                                                a service   \n",
                            "\n",
                            "   is_correct  \n",
                            "0        True  \n",
                            "1        True  \n",
                            "2        True  \n",
                            "3        True  \n",
                            "4        True  \n",
                            "5        True  \n",
                            "6        True  \n",
                            "7        True  \n",
                            "8        True  \n",
                            "9        True  "
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# Create DataFrame\n",
                "df = pd.DataFrame(results)\n",
                "\n",
                "# Calculate Accuracy\n",
                "accuracy = df[\"is_correct\"].mean()\n",
                "print(f\"\\nOverall Accuracy: {accuracy:.2%}\")\n",
                "\n",
                "# Display Results\n",
                "pd.set_option('display.max_colwidth', 100)\n",
                "display(df[[\"question\", \"ground_truth_text\", \"predicted_text\", \"is_correct\"]])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "No incorrect predictions in this sample!\n"
                    ]
                }
            ],
            "source": [
                "# Inspect Reasoning for Incorrect Answers\n",
                "incorrect = df[~df[\"is_correct\"]]\n",
                "if not incorrect.empty:\n",
                "    print(\"\\n--- Analysis of Incorrect Predictions ---\")\n",
                "    for _, row in incorrect.iterrows():\n",
                "        print(f\"\\nQ: {row['question']}\")\n",
                "        print(f\"True: {row['ground_truth_text']} | Pred: {row['predicted_text']}\")\n",
                "        print(f\"Reasoning: {row['reasoning_quality']}\")\n",
                "else:\n",
                "    print(\"No incorrect predictions in this sample!\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "PGM",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.13"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
